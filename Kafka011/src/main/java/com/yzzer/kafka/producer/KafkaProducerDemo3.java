package com.yzzer.kafka.producer;


import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.Properties;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Future;

/**
 * ç”Ÿäº§è€… åŒæ­¥å‘é€
 *
 * é…ç½®ç±» ï¼š
 *      ProducerConfig
 *      CommonClientConfigs
 *      ConsumerConfig
 *
 */

public class KafkaProducerDemo3 {

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        // 0. åˆ›å»ºé…ç½®å¯¹è±¡
        Properties props = new Properties();
        //kafkaé›†ç¾¤ï¼Œbroker-list
        props.put("bootstrap.servers", "hadoop102:9092");

        props.put("acks", "all");

        //é‡è¯•æ¬¡æ•°
        props.put("retries", 3);

        //æ‰¹æ¬¡å¤§å°
        props.put("batch.size", 16384);

        //ç­‰å¾…æ—¶é—´
        props.put("linger.ms", 1);

        //RecordAccumulatorç¼“å†²åŒºå¤§å°
        props.put("buffer.memory", 33554432); // 32M mapreduceæœ¬åœ°æ¨¡å¼å—å¤§å°ä¸º32M

        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");


        // 1. åˆ›å»ºç”Ÿäº§è€…å¯¹è±¡
        KafkaProducer<String, String> kafkaProducer = new KafkaProducer<String, String>(props);

        // 2. ç”Ÿäº§æ•°æ®
        long beforeTime = System.currentTimeMillis();
        long s = 0;
        for (int i = 0; i < 10; i++) {

            Future<RecordMetadata> future =
                    kafkaProducer.send(new ProducerRecord<String, String>("test", "yzzer" + i),
                    new Callback() {
                        /**
                         * å½“æ¶ˆæ¯å‘é€å®Œæˆåï¼Œä¼šè°ƒç”¨è¯¥æ–¹æ³•
                         * @param metadata  æ¶ˆæ¯çš„å…ƒæ•°æ®ä¿¡æ¯-æ¶ˆæ¯å‘åˆ°å“ªé‡Œ
                         * @param exception   æ¶ˆæ¯å‘é€è¿‡ç¨‹å¦‚æœæŠ›å‡ºå¼‚å¸¸ä¼šä¼ å…¥è¯¥æ–¹æ³•
                         */
                        public void onCompletion(RecordMetadata metadata, Exception exception) {
                            if (exception != null) {
                                System.out.println("æ¶ˆæ¯å‘é€å¤±è´¥ï¼š" + exception.getMessage());
                            } else {
                                System.out.println("æ¶ˆæ¯å‘é€æˆåŠŸ: " + metadata.topic() + ":"
                                        + metadata.partition() + ":" + metadata.offset());
                            }
                        }
                    });
            System.out.println("==============æ¶ˆæ¯å‘é€===============");
            future.get();
            System.out.println("==============æ¶ˆæ¯å®Œæˆ===============");
            s += ("yzzer" + i).getBytes().length;

            // å¯ä»¥ç”¨ä¸‹é¢è¿™å¥ğŸ‘‡
//            kafkaProducer.send(new ProducerRecord<String, String>("test", "yzzer" + i)).get();
        }

        // 3. å…³é—­å¯¹è±¡
        kafkaProducer.close();
        System.out.println(s);

    }


}
